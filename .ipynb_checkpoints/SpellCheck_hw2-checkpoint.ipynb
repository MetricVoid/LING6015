{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "v_nDMRV5x1yV"
   },
   "source": [
    "### Your Name: Zhaoran Ma\n",
    "\n",
    "\n",
    "## Section 0: Setup\n",
    "\n",
    "We're going to be using NLTK, Python's \"Natural Language Tool Kit\".\n",
    "\n",
    "You can read more about nltk here: http://www.nltk.org/book/, especially Chapter 2 (http://www.nltk.org/book/ch02.html)\n",
    "\n",
    "Download nltk.  You might have to run:\n",
    "  <ul> import nltk </ul>\n",
    "    <ul> nltk.download() </ul>\n",
    "        \n",
    "        \n",
    "  and then wait until it all installs.\n",
    "  \n",
    "  First let's make sure it's loaded by printing the number of words in \"Emma\".  Please run the cell below and make sure it prints out \"192427\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "_-0VJRl3x1yW",
    "outputId": "26f1cdfe-23d7-4e2d-a46c-ab5eb458a0b1"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "192427"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "emma_words = nltk.corpus.gutenberg.words('austen-emma.txt')\n",
    "len(emma_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xDy2mVdQx1yb"
   },
   "source": [
    "\n",
    "\n",
    "# Section 1: Part-of-Speech Tagging\n",
    "\n",
    "You have probably heard of nouns, verbs, adjectives, prepositions, and so on: \"parts of speech\" (PoS).\n",
    "\n",
    "The Parts of Speech tags often used in computational linguistics are given HERE: https://www.ling.upenn.edu/courses/Fall_2003/ling001/penn_treebank_pos.html\n",
    "\n",
    "This question is adopted from Lucas Champollion and Frans Adriaans.\n",
    "\n",
    "### Question 1\n",
    "Newspaper headlines are famous for being syntactically ambiguous in ways that can be funny.\n",
    "\n",
    "Without doing any programming, please manually assign PoS tags to the following (amusingly ambiguous) newspaper headlines:\n",
    "\n",
    "-- British Left Waffles on Falkland Islands\n",
    "\n",
    "-- Juvenile Court to Try Shooting Defendant\n",
    "\n",
    "-- Miners Refuse to Work After Death\n",
    "\n",
    "-- Iraqi head seeks arms\n",
    "\n",
    "-- Pope's Baby Steps On Gays\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RL4mo56yx1yb"
   },
   "source": [
    "### Your answer to Question 1\n",
    "\n",
    "1. British(JJ) Left(VBD) Waffles(NNS) on(IN) Falkland(NNP) Islands(NNPS)\n",
    "\n",
    "Alternatively, it can be interpreted as \n",
    "\n",
    "- British(JJ) Left(VBD) Waffles(NNP) on(IN) Falkland(NNP) Islands(NNPS)\n",
    "\n",
    "2. In the sentence above, Waffles is a proper noun referring to an island name\n",
    "\n",
    "- Juvenile(JJ) Court(NN) to(TO) Try(VB) Shooting(NN) Defendant(NN)\n",
    "\n",
    "Alternatively, it can be interpretted as \n",
    " \n",
    "\n",
    "- Juvenile(JJ) Court(NN) to(TO) Try(VB) Shooting(VBG) Defendant(NN)\n",
    "\n",
    "\n",
    "3. Miners(NNS) Refuse(VBP) to(TO) Work(VB) After(IN) Death(NN)\n",
    "\n",
    "It can be interpreted as \"Miners refuse to work after their own death\" or \"Miners refuse to work after another miner's death\"\n",
    "\n",
    "4. Iraqi(JJ) head(NN) seeks(VBZ) arms(NNS)\n",
    "\n",
    "It means either \"Iraqi government headquarters seeks firearms\" or \"an Iraqi head (body part) is finding its arms(body part)\"\n",
    "\n",
    "5. Pope(NNP)'s(POS) Baby(NN) Steps(NNS) On(IN) Gays(NNS)\n",
    "\n",
    "Alternatively, it can be interpretted as \n",
    "\n",
    "- Pope(NNP)'s(POS) Baby(NN) Steps(VBZ) On(IN) Gays(NNS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "H9-7O2yex1yc"
   },
   "source": [
    "### Question 2\n",
    "\n",
    "See the following example of how to automatically tag a headline using NLTK's part-of-speech tagger:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "An6_pVmGx1yc",
    "outputId": "c0e7eaf0-ada3-429c-9c6d-8042b15ace5d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('British', 'JJ'), ('left', 'VBD'), ('waffles', 'NNS'), ('on', 'IN'), ('Falkland', 'NNP'), ('Islands', 'NNP')]\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "\n",
    "headline=\"British left waffles on Falkland Islands\"\n",
    "\n",
    "words=nltk.word_tokenize(headline)\n",
    "# this function turns the string into a list of words\n",
    "\n",
    "tags=nltk.pos_tag(words)#  This  function takes in a list of words and then print  out  a  list  of  (word,tag)  pairs\n",
    "\n",
    "print(tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "An6_pVmGx1yc",
    "outputId": "c0e7eaf0-ada3-429c-9c6d-8042b15ace5d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Juvenile', 'NNP'), ('Court', 'NNP'), ('to', 'TO'), ('Try', 'VB'), ('Shooting', 'NNP'), ('Defendant', 'NNP')]\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "\n",
    "headline=\"Juvenile Court to Try Shooting Defendant\"\n",
    "\n",
    "words=nltk.word_tokenize(headline)\n",
    "# this function turns the string into a list of words\n",
    "\n",
    "tags=nltk.pos_tag(words)#  This  function takes in a list of words and then print  out  a  list  of  (word,tag)  pairs\n",
    "\n",
    "print(tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "An6_pVmGx1yc",
    "outputId": "c0e7eaf0-ada3-429c-9c6d-8042b15ace5d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Miners', 'NNS'), ('Refuse', 'NNP'), ('to', 'TO'), ('Work', 'VB'), ('After', 'IN'), ('Death', 'NNP')]\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "\n",
    "headline=\"miners refuse to Work After Death\"\n",
    "\n",
    "words=nltk.word_tokenize(headline)\n",
    "# this function turns the string into a list of words\n",
    "\n",
    "tags=nltk.pos_tag(words)#  This  function takes in a list of words and then print  out  a  list  of  (word,tag)  pairs\n",
    "\n",
    "print(tags)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "asZYRZiIx1ye"
   },
   "source": [
    "Now please automatically tag all of the news headlines from Question 1.\n",
    "\n",
    "Are any of the headlines tagged in a way that the author probably did not intend?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KC4uzQDNx1yf"
   },
   "source": [
    "### Your answer to Question 2\n",
    "\n",
    "1. British Left Waffles on Falkland Islands\n",
    "\n",
    "    * This sentence tag result is [('British', 'JJ'), ('Left', 'NNP'), ('Waffles', 'NNP'), ('on', 'IN'), ('Falkland', 'NNP'), ('Islands', 'NNP')]\n",
    "    * My annotation is different for \"Left\" (VBD) and \"Waffles\" (NNS or NNP depending on the meanings). The unintended labelling for \"Left\" seems to be caused by the capitalization. Every noun was tagged as \"NNP\" because of the same reason. \n",
    "    * I tried lowercase every word and got this new tagging. [('British', 'JJ'), ('left', 'VBD'), ('waffles', 'NNS'), ('on', 'IN'), ('Falkland', 'NNP'), ('Islands', 'NNP')] \n",
    "    * This is consistent with my tagging when considering waffles as a type of food. This might be unintended by the author.\n",
    "\n",
    "2. Juvenile Court to Try Shooting Defendant\n",
    "    * The POS result is [('juvenile', 'JJ'), ('court', 'NN'), ('to', 'TO'), ('try', 'VB'), ('shooting', 'VBG'), ('defendant', 'NN')] (given lowercase words) OR [('Juvenile', 'NNP'), ('Court', 'NNP'), ('to', 'TO'), ('Try', 'VB'), ('Shooting', 'NNP'), ('Defendant', 'NNP')] (given uppercase words)\n",
    "    * The lowercase result label \"shooting\" as \"VBG\", which is consistent with one interpretation. This may be unintended as the author intended to say \"Adolescent Court to Undertake Shooting Respondent\". \n",
    "    \n",
    "3. Miners Refuse to Work After Death\n",
    "    * The POS result is [('Miners', 'NNS'), ('Refuse', 'NNP'), ('to', 'TO'), ('Work', 'VB'), ('After', 'IN'), ('Death', 'NNP')] (given upper case words) OR \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6vlpaNylx1yf"
   },
   "source": [
    "# Section 2 - Edit Distance\n",
    "\n",
    "adapted from Lucas Champollion and Frans Adriaans"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-t7XMcz1x1yg"
   },
   "source": [
    "A  user  types  “halvs”  in  a  document.  This word is a mis-spelling, which we can see from the fact that it does not occur in any dictionary, nor in any set of words taken from a corpus of correctly-spelled words.\n",
    " \n",
    "The  computer  comes  up  with  four  candidate  corrections (as for how these are generated, stay tuned):  -  halves  -  calves  -  halts -  helps."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UQ335zaOx1yg"
   },
   "source": [
    "### Question 3\n",
    "\n",
    "Based only on your intuition (no math or programming needed), please rank those corrections from most to least likely (what did the writer most likely intend?)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rEC_Ph9Ux1yg"
   },
   "source": [
    "### Your answer to Question 3\n",
    "\n",
    "halves > halts > helps > calves \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GLE_N3cTx1yh"
   },
   "source": [
    "### Question 4\n",
    "\n",
    "Next, we'll import a function for calculating edit distance, already given to us in NLTK.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "zB99LofYx1yh"
   },
   "outputs": [],
   "source": [
    "from nltk.metrics.distance import edit_distance\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "pzrgUIAVx1yj",
    "outputId": "76a276f4-a41e-4720-ef68-bb32fdeced63"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "distance between 'halves' and  'halvs'\n",
      "1\n",
      "distance between 'calves' and  'halvs'\n",
      "2\n",
      "distance between 'halts' and  'halvs'\n",
      "1\n",
      "distance between 'helps' and  'halvs'\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "candidates = [\"halves\", \"calves\", \"halts\", \"helps\"]\n",
    "\n",
    "for cand in candidates:\n",
    "    print(\"distance between '\" + cand + \"' and  'halvs'\")\n",
    "    print(edit_distance(cand,\"halvs\"))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gMYxZEP3x1yl"
   },
   "source": [
    "Please explain all 4 of these numbers.  How are they calculated?\n",
    "\n",
    "(As a hint, the operations allowed in \"edit distance\" -- each with a cost of 1 -- are as follows....)\n",
    "\n",
    "insertion: insert a character\n",
    "\n",
    "deletion: delete a character\n",
    "\n",
    "transposition: reverse the order of 2 characters\n",
    "\n",
    "substitution/replacement: replace 1 character with another"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zAF9WNkbx1yl"
   },
   "source": [
    "### Your answer to Question 4\n",
    "\n",
    "1. distance between 'halves' and  'halvs' is 1\n",
    "    - it takes an insertion of 'e' to get from 'halvs' to 'halves' \n",
    "2. distance between 'calves' and  'halvs' is 2\n",
    "    - First step is substitution. We replace 'h' with 'c' and get 'calvs' . The next step is addition. We add 'e' to the second last position and get 'calves' \n",
    "3. distance between 'halts' and  'halvs'\n",
    "    - We substitute 'v' with 't' and get 'halts' \n",
    "4. distance between 'helps' and  'halvs'\n",
    "    - We need to substitute twice. The first step is to replace 'a' with 'e' and get 'helvs'. The second step is to replace 'v' with 'p' and get 'helps'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AzcHrxfBx1ym"
   },
   "source": [
    "### Question 5\n",
    "\n",
    "What further information could you use to decide which of the two closest corrections by edit distance (\"halves\" and \"halts\") should be ranked higher?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uZxLs8q-x1ym"
   },
   "source": [
    "### Your answer to Question 5\n",
    "\n",
    "We can use part-of-speech labels to determine which of the closest corrections match the sentence structure. 'halves' is usually labelled as \"NNS\" while 'halts' is labelled as '\"VBZ\". \n",
    "\n",
    "For example, if the sentence is \"The car halvs\", since 'car' has POS tag \"NN\", it is more likely to be followed by a verb. Thus 'halts' is more likely.\n",
    "\n",
    "If the sentence it \"A chef cut fish in halvs\", as 'in' is labelled 'IN', it it more likely to be followed by a noun. Thus 'halves' is more likely. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CR7JfyaEx1yn"
   },
   "source": [
    "### Question 6\n",
    "\n",
    "Imagine a common mis-spelling of your own name.\n",
    "\n",
    "Use NLTK to calculate the edit distance between the mis-spelling and the correct spelling.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fz85k1-0x1yn"
   },
   "source": [
    "### Your answer to Question 6\n",
    "\n",
    "A common mis-spelling of my name 'Zhaoran' is 'Zhoaran' \n",
    "\n",
    "- distance between 'Zhoaran' and  'Zhaoran' is 2. Although from what we covered from class, only 1 transportion took place and the distance should be 1. I'm assuming the program calculated it as two substitution. \n",
    "\n",
    "- The person mis-spelt might only remember the first syllable has 4 letters and the vowels are 'a','o'. By English spelling convention, it is more common to see 'oa' compared to 'ao' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "distance between 'Zhoaran' and  'Zhaoran'\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "candidates = [\"Zhoaran\"]\n",
    "\n",
    "for cand in candidates:\n",
    "    print(\"distance between '\" + cand + \"' and  'Zhaoran'\")\n",
    "    print(edit_distance(cand,\"Zhaoran\"))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XPPGKON8x1yo"
   },
   "source": [
    "### Question 7\n",
    "\n",
    "Presumably, other possible mis-spellings are also within the same edit-distance of your correctly spelled name as the common mis-spelling you indicated in Question 13.\n",
    "\n",
    "Give an example of some of these other possible mis-spellings.  Calculate its edit distance from your name.\n",
    "\n",
    "Why do you think these less-common mis-spellings are less common?  (Think of the reasons that people make spelling errors -- mis-typing vs. actual confusion about the spelling.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "distance between 'Zhoran' and  'Zhaoran'\n",
      "1\n",
      "distance between 'Chaoran' and  'Zhaoran'\n",
      "1\n",
      "distance between 'Sharon' and  'Zhaoran'\n",
      "3\n"
     ]
    }
   ],
   "source": [
    "candidates = [\"Zhoran\", \"Chaoran\", \"Sharon\"]\n",
    "\n",
    "for cand in candidates:\n",
    "    print(\"distance between '\" + cand + \"' and  'Zhaoran'\")\n",
    "    print(edit_distance(cand,\"Zhaoran\"))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nmcxEHeux1yo"
   },
   "source": [
    "### Your answer to Question 7\n",
    "\n",
    "I also recieve emails with my name (\"Zhaoran\") spelt as \"Zhoran\" or \"Chaoran\". \n",
    "\n",
    "- distance between 'Zhoaran' and  'Zhaoran' is 1. One deletion took place. This is less common than 'Zhoaran' maybe because the amount of characters reduced. \n",
    "\n",
    "- distance between 'Chaoran' and  'Zhaoran' is 1. One substitution took place. Notice this mis-spelling happens more frequently with Mandarin speakers. I assume because \"Chao\" and \"Zhao\" have similar pronunciation in Mandarin. This is less common because the first letter is the most memorizable. Unless they translate the name in their mind before writing it down, the mis-spelling is not likely to happen."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-EUqGhzvx1yo"
   },
   "source": [
    "# Section 3 - Peter Norvig's Spell-Checker\n",
    "\n",
    "The following code is adapted from Google research director Peter Norvig: https://norvig.com/spell-correct.html (please read that web page for discussion).  It's a spell-checker that reads in a word and outputs a spell-checked version of that word.\n",
    "\n",
    "First, we use the Brown Corpus to get a dictionary of words and their frequencies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "g2_wn6o-x1yp"
   },
   "outputs": [],
   "source": [
    "import re\n",
    "from collections import Counter\n",
    "from nltk.corpus import brown\n",
    "\n",
    "\n",
    "WORDS = Counter(brown.words())\n",
    "# we are using the Brown Corpus (part of NLTK) \n",
    "#to get a dictionary of correctly spelled words and their frequencies.\n",
    "# WORDS is a DICTIONARY where the keys are words and the values are the number of \n",
    "# occurrences of that word."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aYPxzyYGx1yr"
   },
   "source": [
    "Let's make that idea concrete by printing out the 20 key/value pairs from WORDS with the highest values.\n",
    "\n",
    "Note that \"u\" means the string is in Unicode.\n",
    "\n",
    "Not surprisingly, when you run the cell below, you will see that \"the, and, of, to\", and various punctuation marks are very common words in the Brown Corpus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "-mVZCkrqx1yr",
    "outputId": "600594d8-e483-4870-92cf-536eda0c4399"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('the', 62713),\n",
       " (',', 58334),\n",
       " ('.', 49346),\n",
       " ('of', 36080),\n",
       " ('and', 27915),\n",
       " ('to', 25732),\n",
       " ('a', 21881),\n",
       " ('in', 19536),\n",
       " ('that', 10237),\n",
       " ('is', 10011),\n",
       " ('was', 9777),\n",
       " ('for', 8841),\n",
       " ('``', 8837),\n",
       " (\"''\", 8789),\n",
       " ('The', 7258),\n",
       " ('with', 7012),\n",
       " ('it', 6723),\n",
       " ('as', 6706),\n",
       " ('he', 6566),\n",
       " ('his', 6466)]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "WORDS.most_common(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "q3u4ych2x1yt"
   },
   "source": [
    "Next, here is Peter Norvig's spell-checker.  (Again, see his blog post for discussion: https://norvig.com/spell-correct.html.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "HLEIAN1Cx1yt"
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def P(word, N=sum(WORDS.values())): \n",
    "    \"Probability of `word`.\"\n",
    "    return WORDS[word] / N\n",
    "\n",
    "def correction(word): \n",
    "    \"Most probable spelling correction for word.\"\n",
    "    return max(candidates(word), key=P)\n",
    "\n",
    "def candidates(word): \n",
    "    \"Generate possible spelling corrections for word.\"\n",
    "    return (known([word]) or known(edits1(word)) or known(edits2(word)) or [word])\n",
    "\n",
    "def known(words): \n",
    "    \"The subset of `words` that appear in the dictionary of WORDS.\"\n",
    "    return set(w for w in words if w in WORDS)\n",
    "\n",
    "def edits1(word):\n",
    "    \"All edits that are one edit away from `word`.\"\n",
    "    letters    = 'abcdefghijklmnopqrstuvwxyz'\n",
    "    splits     = [(word[:i], word[i:])    for i in range(len(word) + 1)]\n",
    "    deletes    = [L + R[1:]               for L, R in splits if R]\n",
    "    transposes = [L + R[1] + R[0] + R[2:] for L, R in splits if len(R)>1]\n",
    "    replaces   = [L + c + R[1:]           for L, R in splits if R for c in letters]\n",
    "    inserts    = [L + c + R               for L, R in splits for c in letters]\n",
    "    return set(deletes + transposes + replaces + inserts)\n",
    "\n",
    "def edits2(word): \n",
    "    \"All edits that are two edits away from `word`.\"\n",
    "    return (e2 for e1 in edits1(word) for e2 in edits1(e1))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CboUb_bfx1yv"
   },
   "source": [
    "Now let's test the code.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "lf-4TDQax1yw",
    "outputId": "0b3a1b07-bef5-4788-c72f-a7635cff4d36"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "corrected\n",
      "correct\n",
      "georiga\n",
      "Georgia\n",
      "georiga\n"
     ]
    }
   ],
   "source": [
    "print(correction(\"corected\"))\n",
    "\n",
    "print(correction(\"correct\"))\n",
    "\n",
    "print(correction(\"georiga\"))\n",
    "\n",
    "print(correction(\"Georiga\"))\n",
    "\n",
    "print(correction(\"georiga\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PidPXelEx1yy"
   },
   "source": [
    "### Question 8\n",
    "\n",
    "What does Norvig's spell-checker do with a word that is ALREADY spelled correctly and does not need to be corrected?  How does the spell-checker \"know\" that the word is already spelled right?  (1-2 sentences)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CDjwayfGx1yy"
   },
   "source": [
    "### Your answer to Question 8\n",
    "\n",
    "1. The spell-checker returns the correct word without modification. \n",
    "2. The spell-checker knows the word is correct because $\\texttt{known([word])}$ results the original word if the word is in WORDS.   \n",
    "    - $\\texttt{(known([word]) or known(edits1(word)) or \n",
    "known(edits2(word)) or [word])}$ will result as the first non-empty set. \n",
    "    - $\\texttt{known([word])}$ function returns the set of $\\textit{known}$ word in $\\texttt{[word]}$ by checking if each word is in $\\textit{WORDS}$\n",
    "    - Since the correct word $\\textit{word}$ is $\\textit{known}$ in $\\textit{WORDS}$, the part before the first \"or\" returns a non-empty set $\\textit{[word]}$. After the OR operations, we get $\\textit{[word]}$ as the final result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MzIHofWux1yy"
   },
   "source": [
    "### Question 9\n",
    "\n",
    "What does Norvig's spell-checker do with a word that IS mis-spelled?\n",
    "\n",
    "How is such a mis-spelling identified?\n",
    "\n",
    "How are the candidate corrections generated?\n",
    "\n",
    "How is the best candidate chosen?\n",
    "\n",
    "What is going on with capitalization?\n",
    "\n",
    "How could Norvig's spell-checker be improved?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yGP09RHyx1yz"
   },
   "source": [
    "### Your answer to Question 9\n",
    "\n",
    "- What does Norvig's spell-checker do with a word that IS mis-spelled?\n",
    "    - It returns the word with highest probability among words one or two edits away from the original word. The priority is $\\textit{original word(correct spelling) > word 1-edit away with highest probability >}$ $\\textit{word 2-edit away with highest probability > original word(no matching in WORDS)}$\n",
    "\n",
    "- How is such a mis-spelling identified?\n",
    "    - As I mentioned earlier, if the word is correct, the function returns the original word. Only if $\\textit{(known([word])}$ fails to return any result will a word be recognized as a mis-spelling\n",
    "\n",
    "- How are the candidate corrections generated?\n",
    "    - The candidate corrections are generated among words 1-edit or 2-edit away from mis-spelt word by $\\texttt{candidates(word)}$ function.\n",
    "    - $\\texttt{edits1(word)}$ function returns the set of words obtainable after one deletion, transposition, replacement or insertion. \n",
    "    - $\\texttt{edits2(word)}$ calls $\\texttt{edits1(word)}$ again for each word in the set returned by $\\texttt{edits1(word)}$. It returns the set of words obtainable after two editions (any order, any two operators or same operator twice, no dupilcated words)\n",
    "    - $\\texttt{known(words)}$ function returns a set of existing words from the input set of words. \n",
    "    - $\\texttt{candidates(word)}$ calls $\\texttt{known(words)}$ on set of words 0, 1, 2 edits away from the word. If the word 0 edit away is a valid word, return the original word. If any word 1 edit away is valid and the word 0 edit away is not valid, return the set of words 1 edit away. Similar for set of words 2 edits away. That's how the candidate corrections are generated.\n",
    "\n",
    "- How is the best candidate chosen?\n",
    "    - candidate is chosen by $\\texttt{correction(word)}$. This function calls $\\texttt{candidates(word)}$ which returns a set of valid words.\n",
    "    - In the function, it find the candidate with a max probability of appearing in the valid word set $\\textit{WORDS}$ we provided. That's how it finds the best candidate.\n",
    "\n",
    "- What is going on with capitalization?\n",
    "    - In the code above, it keeps capitalization when comparing with words in WORDS. For example, \"Georgia\" is a valid word. $\\texttt{edits1(word)}$ will not change a lowercased word to uppercased. It could generate \"georgia\" \"Giorgia\" from \"Georgia\" but not \"Aeorgia\". \n",
    "\n",
    "- How could Norvig's spell-checker be improved?\n",
    "    - It can be improved if the best candidate is not selected by the most likely word in WORDS, instead, by the most likely n-gram with the phrase it forms. This could find a better fit in context."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KFu_QIXrx1yz"
   },
   "source": [
    "## Question 10\n",
    "\n",
    "An \"OOV item\" is an \"out-of-vocabulary item.\"  Norvig's spellchecker is based on the idea that all OOV items need to be spell-corrected to be turned into in-vocabulary items.  But actually, this is not true; perhaps the word is simply a correct spelling of a NEW word that the spellchecker has never seen before.\n",
    "\n",
    "This Twitter account (https://twitter.com/nyt_first_said?lang=en) automatically documents new words used for the first time in the New York Times.  Even though they are all by definition OOV items, most of them are NOT typos, so they should actually not be corrected by a spell-checker.  Learning how to deal with OOV items -- both their spelling and their meaning -- is an important topic in current NLP research.  A graduate student at Georgia Tech named Yuval Pinter is working on this topic for his thesis, partly using these NYT data.\n",
    "\n",
    "Please spend some time reading these new words.  Can you group them into any meaningful categories?  Can you brainstorm any possible ways that they might be (automatically) recognized as new words rather than mis-spellings of existing words?  For example, can you think of any way to automate what you are already doing yourself when you recognize them as such?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HyUVo-Jcx1y0"
   },
   "source": [
    "## Your answer to Question 10\n",
    "\n",
    "- Possible categories\n",
    "    - variation of existing words or phrases \n",
    "        - \"lit'racy\" (looks like an AAVE expression of it's racist)\n",
    "        - \"disapparating\" (variation of \"disappointing\") \n",
    "        - skinnn\n",
    "        - navigans\n",
    "    - new words formed by combining existing words \n",
    "        - \"megarisks\" (\"mega\" + \"risks\") \n",
    "        - \"microgrids\"\n",
    "        - \"middinner\"\n",
    "        - \"prehumanity\n",
    "    - greetings or sounds\n",
    "        - \"aaarghhh\"\n",
    "    - jargons \n",
    "        - travishers (A carpenter's shave designed for shaping and smoothing concave surfaces)\n",
    "        - phylogenomicist\n",
    "        - striolated (bird species) \n",
    "    - words imported from other languages \n",
    "        - brunetus (brown, Latin) \n",
    "        - tribales (tribal, Spanish)\n",
    "        - kuromutsu (a type of fish, Japanese)\n",
    "        - zhawendidaa, wiidookodaadidaa (drum heater, Ojibwe Indian) \n",
    "    - name/ proper nouns \n",
    "        - za’eem (boy's name)\n",
    "- Why they are new words rather than mis-spellings \n",
    "    - Overall, these words have different meanings or effects when used in conversations or writing\n",
    "    - For words from different cultural origin, many bilinguals use words that can't be properly replaced by another word in English, or if they want to provide a context of the cultural reference. \"Hanami\" is one example. It means watch flowers (sakura blossoms) with friends and family in spring. In English, I can't express the same meaning with a simple word or phrase.\n",
    "    - For jargons, it has a new definition and is used to keep communication professional. \n",
    "    - For variation of existing words, they are usually more of oral language that make users feel initimate or connected to another user. It serves a sentiment purpose more than conveying content itself.\n",
    "    - For new words combined with existing words / prefix, it has a new meaning. \"Megarisks\" are really serious risks. Sometimes I say I \"megalove\" the design of a jewel. \n",
    "    - Because the NYT words convey different meanings or sentiments, these new words shouldn't be recognized as mis-spellings. Additionally, they are a lot of edits away from the original word (if we assume there is one). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KuaPRtAFx1y1"
   },
   "source": [
    "### Question 11\n",
    "\n",
    "Please read the \"Encodings\" chapter of the in-progress TEXTBOOK DRAFT posted to Canvas, and use bullet points to indicate 3 things you learned as well as 1 or 2 constructive suggestions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QT8GKzNUx1y1"
   },
   "source": [
    "### Your answer to Question 11\n",
    "\n",
    "- What I learned\n",
    "    - To represent spoken language digitally,we need to understand both the artifulatory properties and the acoustic properties of the speech. \n",
    "    - Acoustic properties are ususally studied in spectrograms, which represent the frequencies over time. We can read the spectrograms by how dark the area is (how loud the sound is) and distinguish fricatives, aspirations, and vowels from the diagrams. \n",
    "    - Automatic speech recognition(ASR) is a process where computer converts speech into text. It converts continous speech intro discrete representations and then recognize each of the units and transcribe into text. \n",
    "- Suggestions\n",
    "    - I really like how  1.3 writing systems explains every concept with example languages. It would be nicer if there's a sample of a sentence/ writing in each of the language mentioned and give readers a sense of what it is like. It doesn't need to be the whole alphabet, just 1 or 2 sounds/ words should be good. \n",
    "    - Url in text interrupt reading a bit. Would be nicer if the links are listed at the bottom margin of each page."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GnmRA-kCVj73"
   },
   "source": [
    "## Question 12"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HJ3oIghqVpTe"
   },
   "source": [
    "Please read the \"Writers Aids\" chapter of the in-progress TEXTBOOK DRAFT posted to Canvas, and use bullet points to indicate 3 things you learned as well as 1 or 2 constructive suggestions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7WNjv_M9VqB-"
   },
   "source": [
    "### Your answer to Question 12"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "apM5pPqbVrpu"
   },
   "source": [
    "- What I learnt\n",
    "    - We can rank word candidates by using noise channel model, calculating the minimum edit distance, or calculating n-grams.\n",
    "    - Style checkers can suggest avoiding passive tence, varying sentences lengths etc. But it could be hard to check if the idea of the current sentence is already established in the previous sentence. \n",
    "    - Dependency checker can be universally applicable for multiple languages as it represents the relationships between adjacent words.\n",
    "    \n",
    "- Suggestion\n",
    "    - I really like the discussion in 2.7 about auto-complete and it would be nice to add additional resources/ papers for readers to check out.\n",
    "- Typo \n",
    "    - page 53 Under the Hood index is not rendered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "SpellCheck_hw2.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
