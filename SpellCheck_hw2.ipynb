{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "v_nDMRV5x1yV"
   },
   "source": [
    "# Your Name:\n",
    "\n",
    "\n",
    "## Section 0: Setup\n",
    "\n",
    "We're going to be using NLTK, Python's \"Natural Language Tool Kit\".\n",
    "\n",
    "You can read more about nltk here: http://www.nltk.org/book/, especially Chapter 2 (http://www.nltk.org/book/ch02.html)\n",
    "\n",
    "Download nltk.  You might have to run:\n",
    "  <ul> import nltk </ul>\n",
    "    <ul> nltk.download() </ul>\n",
    "        \n",
    "        \n",
    "  and then wait until it all installs.\n",
    "  \n",
    "  First let's make sure it's loaded by printing the number of words in \"Emma\".  Please run the cell below and make sure it prints out \"192427\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "_-0VJRl3x1yW",
    "outputId": "26f1cdfe-23d7-4e2d-a46c-ab5eb458a0b1"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "192427"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "emma_words = nltk.corpus.gutenberg.words('austen-emma.txt')\n",
    "len(emma_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xDy2mVdQx1yb"
   },
   "source": [
    "\n",
    "\n",
    "# Section 1: Part-of-Speech Tagging\n",
    "\n",
    "You have probably heard of nouns, verbs, adjectives, prepositions, and so on: \"parts of speech\" (PoS).\n",
    "\n",
    "The Parts of Speech tags often used in computational linguistics are given HERE: https://www.ling.upenn.edu/courses/Fall_2003/ling001/penn_treebank_pos.html\n",
    "\n",
    "This question is adopted from Lucas Champollion and Frans Adriaans.\n",
    "\n",
    "### Question 1\n",
    "Newspaper headlines are famous for being syntactically ambiguous in ways that can be funny.\n",
    "\n",
    "Without doing any programming, please manually assign PoS tags to the following (amusingly ambiguous) newspaper headlines:\n",
    "\n",
    "-- British Left Waffles on Falkland Islands\n",
    "\n",
    "-- Juvenile Court to Try Shooting Defendant\n",
    "\n",
    "-- Miners Refuse to Work After Death\n",
    "\n",
    "-- Iraqi head seeks arms\n",
    "\n",
    "-- Pope's Baby Steps On Gays\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RL4mo56yx1yb"
   },
   "source": [
    "### Your answer to Question 1\n",
    "\n",
    "1. British(JJ) Left(VBD) Waffles(NNS) on(IN) Falkland(NNP) Islands(NNPS)\n",
    "\n",
    "Alternatively, it can be interpreted as \n",
    "\n",
    "- British(JJ) Left(VBD) Waffles(NNP) on(IN) Falkland(NNP) Islands(NNPS)\n",
    "\n",
    "2. In the sentence above, Waffles is a proper noun referring to an island name\n",
    "\n",
    "- Juvenile(JJ) Court(NN) to(TO) Try(VB) Shooting(NN) Defendant(NN)\n",
    "\n",
    "Alternatively, it can be interpretted as \n",
    " \n",
    "\n",
    "- Juvenile(JJ) Court(NN) to(TO) Try(VB) Shooting(VBG) Defendant(NN)\n",
    "\n",
    "\n",
    "3. Miners(NNS) Refuse(VBP) to(TO) Work(VB) After(IN) Death(NN)\n",
    "\n",
    "It can be interpreted as \"Miners refuse to work after their own death\" or \"Miners refuse to work after another miner's death\"\n",
    "\n",
    "4. Iraqi(JJ) head(NN) seeks(VBZ) arms(NNS)\n",
    "\n",
    "It means either \"Iraqi government headquarters seeks firearms\" or \"an Iraqi head (body part) is finding its arms(body part)\"\n",
    "\n",
    "5. Pope(NNP)'s(POS) Baby(NN) Steps(NNS) On(IN) Gays(NNS)\n",
    "\n",
    "Alternatively, it can be interpretted as \n",
    "\n",
    "- Pope(NNP)'s(POS) Baby(NN) Steps(VBZ) On(IN) Gays(NNS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "H9-7O2yex1yc"
   },
   "source": [
    "### Question 2\n",
    "\n",
    "See the following example of how to automatically tag a headline using NLTK's part-of-speech tagger:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "An6_pVmGx1yc",
    "outputId": "c0e7eaf0-ada3-429c-9c6d-8042b15ace5d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('British', 'JJ'), ('left', 'VBD'), ('waffles', 'NNS'), ('on', 'IN'), ('Falkland', 'NNP'), ('Islands', 'NNP')]\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "\n",
    "headline=\"British left waffles on Falkland Islands\"\n",
    "\n",
    "words=nltk.word_tokenize(headline)\n",
    "# this function turns the string into a list of words\n",
    "\n",
    "tags=nltk.pos_tag(words)#  This  function takes in a list of words and then print  out  a  list  of  (word,tag)  pairs\n",
    "\n",
    "print(tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "An6_pVmGx1yc",
    "outputId": "c0e7eaf0-ada3-429c-9c6d-8042b15ace5d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Juvenile', 'NNP'), ('Court', 'NNP'), ('to', 'TO'), ('Try', 'VB'), ('Shooting', 'NNP'), ('Defendant', 'NNP')]\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "\n",
    "headline=\"Juvenile Court to Try Shooting Defendant\"\n",
    "\n",
    "words=nltk.word_tokenize(headline)\n",
    "# this function turns the string into a list of words\n",
    "\n",
    "tags=nltk.pos_tag(words)#  This  function takes in a list of words and then print  out  a  list  of  (word,tag)  pairs\n",
    "\n",
    "print(tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "An6_pVmGx1yc",
    "outputId": "c0e7eaf0-ada3-429c-9c6d-8042b15ace5d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Miners', 'NNS'), ('Refuse', 'NNP'), ('to', 'TO'), ('Work', 'VB'), ('After', 'IN'), ('Death', 'NNP')]\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "\n",
    "headline=\"miners refuse to Work After Death\"\n",
    "\n",
    "words=nltk.word_tokenize(headline)\n",
    "# this function turns the string into a list of words\n",
    "\n",
    "tags=nltk.pos_tag(words)#  This  function takes in a list of words and then print  out  a  list  of  (word,tag)  pairs\n",
    "\n",
    "print(tags)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "asZYRZiIx1ye"
   },
   "source": [
    "Now please automatically tag all of the news headlines from Question 1.\n",
    "\n",
    "Are any of the headlines tagged in a way that the author probably did not intend?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KC4uzQDNx1yf"
   },
   "source": [
    "### Your answer to Question 2\n",
    "\n",
    "1. British Left Waffles on Falkland Islands\n",
    "\n",
    "    * This sentence tag result is [('British', 'JJ'), ('Left', 'NNP'), ('Waffles', 'NNP'), ('on', 'IN'), ('Falkland', 'NNP'), ('Islands', 'NNP')]\n",
    "    * My annotation is different for \"Left\" (VBD) and \"Waffles\" (NNS or NNP depending on the meanings). The unintended labelling for \"Left\" seems to be caused by the capitalization. Every noun was tagged as \"NNP\" because of the same reason. \n",
    "    * I tried lowercase every word and got this new tagging. [('British', 'JJ'), ('left', 'VBD'), ('waffles', 'NNS'), ('on', 'IN'), ('Falkland', 'NNP'), ('Islands', 'NNP')] \n",
    "    * This is consistent with my tagging when considering waffles as a type of food. This might be unintended by the author.\n",
    "\n",
    "2. Juvenile Court to Try Shooting Defendant\n",
    "    * The POS result is [('juvenile', 'JJ'), ('court', 'NN'), ('to', 'TO'), ('try', 'VB'), ('shooting', 'VBG'), ('defendant', 'NN')] (given lowercase words) OR [('Juvenile', 'NNP'), ('Court', 'NNP'), ('to', 'TO'), ('Try', 'VB'), ('Shooting', 'NNP'), ('Defendant', 'NNP')] (given uppercase words)\n",
    "    * The lowercase result label \"shooting\" as \"VBG\", which is consistent with one interpretation. This may be unintended as the author intended to say \"Adolescent Court to Undertake Shooting Respondent\". \n",
    "    \n",
    "3. Miners Refuse to Work After Death\n",
    "    * The POS result is [('Miners', 'NNS'), ('Refuse', 'NNP'), ('to', 'TO'), ('Work', 'VB'), ('After', 'IN'), ('Death', 'NNP')] (given upper case words) OR \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6vlpaNylx1yf"
   },
   "source": [
    "# Section 2 - Edit Distance\n",
    "\n",
    "adapted from Lucas Champollion and Frans Adriaans"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-t7XMcz1x1yg"
   },
   "source": [
    "A  user  types  “halvs”  in  a  document.  This word is a mis-spelling, which we can see from the fact that it does not occur in any dictionary, nor in any set of words taken from a corpus of correctly-spelled words.\n",
    " \n",
    "The  computer  comes  up  with  four  candidate  corrections (as for how these are generated, stay tuned):  -  halves  -  calves  -  halts -  helps."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UQ335zaOx1yg"
   },
   "source": [
    "### Question 3\n",
    "\n",
    "Based only on your intuition (no math or programming needed), please rank those corrections from most to least likely (what did the writer most likely intend?)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rEC_Ph9Ux1yg"
   },
   "source": [
    "### Your answer to Question 3\n",
    "\n",
    "halves > halts > helps > calves \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GLE_N3cTx1yh"
   },
   "source": [
    "### Question 4\n",
    "\n",
    "Next, we'll import a function for calculating edit distance, already given to us in NLTK.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "zB99LofYx1yh"
   },
   "outputs": [],
   "source": [
    "from nltk.metrics.distance import edit_distance\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "pzrgUIAVx1yj",
    "outputId": "76a276f4-a41e-4720-ef68-bb32fdeced63"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "distance between 'halves' and  'halvs'\n",
      "1\n",
      "distance between 'calves' and  'halvs'\n",
      "2\n",
      "distance between 'halts' and  'halvs'\n",
      "1\n",
      "distance between 'helps' and  'halvs'\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "candidates = [\"halves\", \"calves\", \"halts\", \"helps\"]\n",
    "\n",
    "for cand in candidates:\n",
    "    print(\"distance between '\" + cand + \"' and  'halvs'\")\n",
    "    print(edit_distance(cand,\"halvs\"))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gMYxZEP3x1yl"
   },
   "source": [
    "Please explain all 4 of these numbers.  How are they calculated?\n",
    "\n",
    "(As a hint, the operations allowed in \"edit distance\" -- each with a cost of 1 -- are as follows....)\n",
    "\n",
    "insertion: insert a character\n",
    "\n",
    "deletion: delete a character\n",
    "\n",
    "transposition: reverse the order of 2 characters\n",
    "\n",
    "substitution/replacement: replace 1 character with another"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zAF9WNkbx1yl"
   },
   "source": [
    "### Your answer to Question 4\n",
    "\n",
    "1. distance between 'halves' and  'halvs' is 1\n",
    "    - it takes an insertion of 'e' to get from 'halvs' to 'halves' \n",
    "2. distance between 'calves' and  'halvs' is 2\n",
    "    - First step is substitution. We replace 'h' with 'c' and get 'calvs' . The next step is addition. We add 'e' to the second last position and get 'calves' \n",
    "3. distance between 'halts' and  'halvs'\n",
    "    - We substitute 'v' with 't' and get 'halts' \n",
    "4. distance between 'helps' and  'halvs'\n",
    "    - We need to substitute twice. The first step is to replace 'a' with 'e' and get 'helvs'. The second step is to replace 'v' with 'p' and get 'helps'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AzcHrxfBx1ym"
   },
   "source": [
    "### Question 5\n",
    "\n",
    "What further information could you use to decide which of the two closest corrections by edit distance (\"halves\" and \"halts\") should be ranked higher?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uZxLs8q-x1ym"
   },
   "source": [
    "### Your answer to Question 5\n",
    "\n",
    "We can use part-of-speech labels to determine which of the closest corrections match the sentence structure. 'halves' is usually labelled as \"NNS\" while 'halts' is labelled as '\"VBZ\". \n",
    "\n",
    "For example, if the sentence is \"The car halvs\", since 'car' has POS tag \"NN\", it is more likely to be followed by a verb. Thus 'halts' is more likely.\n",
    "\n",
    "If the sentence it \"A chef cut fish in halvs\", as 'in' is labelled 'IN', it it more likely to be followed by a noun. Thus 'halves' is more likely. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CR7JfyaEx1yn"
   },
   "source": [
    "### Question 6\n",
    "\n",
    "Imagine a common mis-spelling of your own name.\n",
    "\n",
    "Use NLTK to calculate the edit distance between the mis-spelling and the correct spelling.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fz85k1-0x1yn"
   },
   "source": [
    "### Your answer to Question 6\n",
    "\n",
    "A common mis-spelling of my name 'Zhaoran' is 'Zhoaran' \n",
    "\n",
    "- distance between 'Zhoaran' and  'Zhaoran' is 2. Although from what we covered from class, only 1 transportion took place and the distance should be 1. I'm assuming the program calculated it as two substitution. \n",
    "\n",
    "- The person mis-spelt might only remember the first syllable has 4 letters and the vowels are 'a','o'. By English spelling convention, it is more common to see 'oa' compared to 'ao' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "distance between 'Zhoaran' and  'Zhaoran'\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "candidates = [\"Zhoaran\"]\n",
    "\n",
    "for cand in candidates:\n",
    "    print(\"distance between '\" + cand + \"' and  'Zhaoran'\")\n",
    "    print(edit_distance(cand,\"Zhaoran\"))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XPPGKON8x1yo"
   },
   "source": [
    "### Question 7\n",
    "\n",
    "Presumably, other possible mis-spellings are also within the same edit-distance of your correctly spelled name as the common mis-spelling you indicated in Question 13.\n",
    "\n",
    "Give an example of some of these other possible mis-spellings.  Calculate its edit distance from your name.\n",
    "\n",
    "Why do you think these less-common mis-spellings are less common?  (Think of the reasons that people make spelling errors -- mis-typing vs. actual confusion about the spelling.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "distance between 'Zhoran' and  'Zhaoran'\n",
      "1\n",
      "distance between 'Chaoran' and  'Zhaoran'\n",
      "1\n",
      "distance between 'Sharon' and  'Zhaoran'\n",
      "3\n"
     ]
    }
   ],
   "source": [
    "candidates = [\"Zhoran\", \"Chaoran\", \"Sharon\"]\n",
    "\n",
    "for cand in candidates:\n",
    "    print(\"distance between '\" + cand + \"' and  'Zhaoran'\")\n",
    "    print(edit_distance(cand,\"Zhaoran\"))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nmcxEHeux1yo"
   },
   "source": [
    "### Your answer to Question 7\n",
    "\n",
    "I also recieve emails with my name (\"Zhaoran\") spelt as \"Zhoran\", \"Chaoran\" or 'Sharon'. \n",
    "\n",
    "- distance between 'Zhoaran' and  'Zhaoran' is 1. One deletion took place. This is less common than 'Zhoaran' maybe because the amount of characters reduced. \n",
    "\n",
    "- distance between 'Chaoran' and  'Zhaoran' is 1. One substitution took place. Notice this mis-spelling happens more frequently with Mandarin speakers. I assume because \"Chao\" and \"Zhao\" have similar pronunciation in Mandarin. This is less common because the first letter is the most memorizable. Unless they translate the name in their mind before writing it down, the mis-spelling is not likely to happen.\n",
    "\n",
    "- distance between 'Sharon' and  'Zhaoran' is 3. There're 2 substitution and one deletion took place. A French teacher who lives in the States always spell my name as 'Sharon'. This mis-spelling is less common because the edit distance is long. It only occurs when someone listens to the pronunciation and write it down as a transcript without looking at the original word."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-EUqGhzvx1yo"
   },
   "source": [
    "# Section 3 - Peter Norvig's Spell-Checker\n",
    "\n",
    "The following code is adapted from Google research director Peter Norvig: https://norvig.com/spell-correct.html (please read that web page for discussion).  It's a spell-checker that reads in a word and outputs a spell-checked version of that word.\n",
    "\n",
    "First, we use the Brown Corpus to get a dictionary of words and their frequencies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "g2_wn6o-x1yp"
   },
   "outputs": [],
   "source": [
    "import re\n",
    "from collections import Counter\n",
    "from nltk.corpus import brown\n",
    "\n",
    "\n",
    "WORDS = Counter(brown.words())\n",
    "# we are using the Brown Corpus (part of NLTK) \n",
    "#to get a dictionary of correctly spelled words and their frequencies.\n",
    "# WORDS is a DICTIONARY where the keys are words and the values are the number of \n",
    "# occurrences of that word."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aYPxzyYGx1yr"
   },
   "source": [
    "Let's make that idea concrete by printing out the 20 key/value pairs from WORDS with the highest values.\n",
    "\n",
    "Note that \"u\" means the string is in Unicode.\n",
    "\n",
    "Not surprisingly, when you run the cell below, you will see that \"the, and, of, to\", and various punctuation marks are very common words in the Brown Corpus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "-mVZCkrqx1yr",
    "outputId": "600594d8-e483-4870-92cf-536eda0c4399"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('the', 62713),\n",
       " (',', 58334),\n",
       " ('.', 49346),\n",
       " ('of', 36080),\n",
       " ('and', 27915),\n",
       " ('to', 25732),\n",
       " ('a', 21881),\n",
       " ('in', 19536),\n",
       " ('that', 10237),\n",
       " ('is', 10011),\n",
       " ('was', 9777),\n",
       " ('for', 8841),\n",
       " ('``', 8837),\n",
       " (\"''\", 8789),\n",
       " ('The', 7258),\n",
       " ('with', 7012),\n",
       " ('it', 6723),\n",
       " ('as', 6706),\n",
       " ('he', 6566),\n",
       " ('his', 6466)]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "WORDS.most_common(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "q3u4ych2x1yt"
   },
   "source": [
    "Next, here is Peter Norvig's spell-checker.  (Again, see his blog post for discussion: https://norvig.com/spell-correct.html.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "HLEIAN1Cx1yt"
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def P(word, N=sum(WORDS.values())): \n",
    "    \"Probability of `word`.\"\n",
    "    return WORDS[word] / N\n",
    "\n",
    "def correction(word): \n",
    "    \"Most probable spelling correction for word.\"\n",
    "    return max(candidates(word), key=P)\n",
    "\n",
    "def candidates(word): \n",
    "    \"Generate possible spelling corrections for word.\"\n",
    "    return (known([word]) or known(edits1(word)) or known(edits2(word)) or [word])\n",
    "\n",
    "def known(words): \n",
    "    \"The subset of `words` that appear in the dictionary of WORDS.\"\n",
    "    return set(w for w in words if w in WORDS)\n",
    "\n",
    "def edits1(word):\n",
    "    \"All edits that are one edit away from `word`.\"\n",
    "    letters    = 'abcdefghijklmnopqrstuvwxyz'\n",
    "    splits     = [(word[:i], word[i:])    for i in range(len(word) + 1)]\n",
    "    deletes    = [L + R[1:]               for L, R in splits if R]\n",
    "    transposes = [L + R[1] + R[0] + R[2:] for L, R in splits if len(R)>1]\n",
    "    replaces   = [L + c + R[1:]           for L, R in splits if R for c in letters]\n",
    "    inserts    = [L + c + R               for L, R in splits for c in letters]\n",
    "    return set(deletes + transposes + replaces + inserts)\n",
    "\n",
    "def edits2(word): \n",
    "    \"All edits that are two edits away from `word`.\"\n",
    "    return (e2 for e1 in edits1(word) for e2 in edits1(e1))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CboUb_bfx1yv"
   },
   "source": [
    "Now let's test the code.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "lf-4TDQax1yw",
    "outputId": "0b3a1b07-bef5-4788-c72f-a7635cff4d36"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "corrected\n",
      "correct\n",
      "georiga\n",
      "Georgia\n",
      "georiga\n"
     ]
    }
   ],
   "source": [
    "print(correction(\"corected\"))\n",
    "\n",
    "print(correction(\"correct\"))\n",
    "\n",
    "print(correction(\"georiga\"))\n",
    "\n",
    "print(correction(\"Georiga\"))\n",
    "\n",
    "print(correction(\"georiga\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PidPXelEx1yy"
   },
   "source": [
    "### Question 8\n",
    "\n",
    "What does Norvig's spell-checker do with a word that is ALREADY spelled correctly and does not need to be corrected?  How does the spell-checker \"know\" that the word is already spelled right?  (1-2 sentences)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CDjwayfGx1yy"
   },
   "source": [
    "### Your answer to Question 8\n",
    "\n",
    "(PLEASE PUT YOUR ANSWER HERE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MzIHofWux1yy"
   },
   "source": [
    "### Question 9\n",
    "\n",
    "What does Norvig's spell-checker do with a word that IS mis-spelled?\n",
    "\n",
    "How is such a mis-spelling identified?\n",
    "\n",
    "How are the candidate corrections generated?\n",
    "\n",
    "How is the best candidate chosen?\n",
    "\n",
    "What is going on with capitalization?\n",
    "\n",
    "How could Norvig's spell-checker be improved?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yGP09RHyx1yz"
   },
   "source": [
    "### Your answer to Question 9\n",
    "\n",
    "(PLEASE PUT YOUR ANSWER HERE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KFu_QIXrx1yz"
   },
   "source": [
    "## Question 10\n",
    "\n",
    "An \"OOV item\" is an \"out-of-vocabulary item.\"  Norvig's spellchecker is based on the idea that all OOV items need to be spell-corrected to be turned into in-vocabulary items.  But actually, this is not true; perhaps the word is simply a correct spelling of a NEW word that the spellchecker has never seen before.\n",
    "\n",
    "This Twitter account (https://twitter.com/nyt_first_said?lang=en) automatically documents new words used for the first time in the New York Times.  Even though they are all by definition OOV items, most of them are NOT typos, so they should actually not be corrected by a spell-checker.  Learning how to deal with OOV items -- both their spelling and their meaning -- is an important topic in current NLP research.  A graduate student at Georgia Tech named Yuval Pinter is working on this topic for his thesis, partly using these NYT data.\n",
    "\n",
    "Please spend some time reading these new words.  Can you group them into any meaningful categories?  Can you brainstorm any possible ways that they might be (automatically) recognized as new words rather than mis-spellings of existing words?  For example, can you think of any way to automate what you are already doing yourself when you recognize them as such?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HyUVo-Jcx1y0"
   },
   "source": [
    "## Your answer to Question 10\n",
    "\n",
    "goes here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KuaPRtAFx1y1"
   },
   "source": [
    "### Question 11\n",
    "\n",
    "Please read the \"Encodings\" chapter of the in-progress TEXTBOOK DRAFT posted to Canvas, and use bullet points to indicate 3 things you learned as well as 1 or 2 constructive suggestions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QT8GKzNUx1y1"
   },
   "source": [
    "### Your answer to Question 11\n",
    "\n",
    "(PLEASE PUT YOUR ANSWER HERE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2K9FjB3dx1y2"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GnmRA-kCVj73"
   },
   "source": [
    "## Question 12"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HJ3oIghqVpTe"
   },
   "source": [
    "Please read the \"Writers Aids\" chapter of the in-progress TEXTBOOK DRAFT posted to Canvas, and use bullet points to indicate 3 things you learned as well as 1 or 2 constructive suggestions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7WNjv_M9VqB-"
   },
   "source": [
    "### Your answer to Question 12"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "apM5pPqbVrpu"
   },
   "source": [
    "goes here"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "SpellCheck_hw2.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
